{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","toc_visible":true,"authorship_tag":"ABX9TyPp6dlsER8+xPVYevAxrx0X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["\"\"\"\n","This notebook is modified from,\n","https://github.com/cloneofsimo/minDiffusion and https://www.kaggle.com/code/ebrahimelgazar/diffusion-model-u-net\n","\n","\"\"\""],"metadata":{"id":"r_M1Vbc1A4U0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"eTO8hXu0EIiz","executionInfo":{"status":"ok","timestamp":1715889392127,"user_tz":-180,"elapsed":2663,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"outputs":[],"source":["from typing import Dict, Tuple\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import models, transforms\n","from torchvision.datasets import CIFAR10\n","from torchvision.utils import save_image, make_grid\n","import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation, PillowWriter\n","import numpy as np"]},{"cell_type":"code","source":["# If you use colab and want to save to your google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQ-WPbQ4Ef3f","executionInfo":{"status":"ok","timestamp":1715889394429,"user_tz":-180,"elapsed":2303,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}},"outputId":"7a03fe37-fe15-4e59-f7d1-77299a9f2fa2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Colab GPU information\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-jt4gZmEgy2","executionInfo":{"status":"ok","timestamp":1715889395131,"user_tz":-180,"elapsed":705,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}},"outputId":"9461069d-1174-4789-83ca-7c62c1f20d13"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu May 16 19:56:34 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0              46W / 400W |      2MiB / 40960MiB |      0%      Default |\n","|                                         |                      |             Disabled |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["class ResidualConvBlock(nn.Module):\n","    def __init__(\n","        self, in_channels: int, out_channels: int, is_res: bool = False\n","    ) -> None:\n","        super().__init__()\n","\n","        self.same_channels = in_channels==out_channels\n","        self.is_res = is_res\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.SiLU(),\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.SiLU(),\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.SiLU(),\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        if self.is_res:\n","            x1 = self.conv1(x)\n","            x2 = self.conv2(x1)\n","\n","            if self.same_channels:\n","                out = x + x2\n","            else:\n","                out = x1 + x2\n","            return out / 1.414\n","        else:\n","            x1 = self.conv1(x)\n","            x2 = self.conv2(x1)\n","            return x2"],"metadata":{"id":"GujBPoLREjCy","executionInfo":{"status":"ok","timestamp":1715889395132,"user_tz":-180,"elapsed":5,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class UnetDown(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UnetDown, self).__init__()\n","        layers = [ResidualConvBlock(in_channels, out_channels), nn.MaxPool2d(2)]\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.model(x)"],"metadata":{"id":"z1FGOLyKEkCi","executionInfo":{"status":"ok","timestamp":1715889395132,"user_tz":-180,"elapsed":5,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class UnetUp(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UnetUp, self).__init__()\n","\n","        layers = [\n","            nn.ConvTranspose2d(in_channels, out_channels, 2, 2),\n","            ResidualConvBlock(out_channels, out_channels),\n","            ResidualConvBlock(out_channels, out_channels),\n","        ]\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, x, skip):\n","        x = torch.cat((x, skip), 1)\n","        x = self.model(x)\n","        return x"],"metadata":{"id":"UXfoqIzPElyW","executionInfo":{"status":"ok","timestamp":1715889395132,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class EmbedFC(nn.Module):\n","    def __init__(self, input_dim, emb_dim):\n","        super(EmbedFC, self).__init__()\n","\n","        self.input_dim = input_dim\n","        layers = [\n","            nn.Linear(input_dim, emb_dim),\n","            nn.SiLU(),\n","            nn.Linear(emb_dim, emb_dim),\n","\n","        ]\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = x.view(-1, self.input_dim)\n","        return self.model(x)"],"metadata":{"id":"OAwLWEzZEmtN","executionInfo":{"status":"ok","timestamp":1715889395132,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# In this section, in addition to the relevant work, a new \"Down\" and \"Up\" layer has been added.\n","# Likewise for time and context embeddings\n","class ContextUnet(nn.Module):\n","    def __init__(self, in_channels, n_feat = 256, n_classes=10):\n","        super(ContextUnet, self).__init__()\n","\n","        self.in_channels = in_channels\n","        self.n_feat = n_feat\n","        self.n_classes = n_classes\n","\n","        self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res=True)\n","\n","        self.down1 = UnetDown(n_feat, n_feat)\n","        self.down2 = UnetDown(n_feat, 2 * n_feat)\n","        self.down3 = UnetDown(2 * n_feat, 2 * n_feat)\n","\n","        self.to_vec = nn.Sequential(nn.AvgPool2d(4), nn.SiLU())\n","\n","        self.timeembed1 = EmbedFC(1, 2*n_feat)\n","        self.timeembed2 = EmbedFC(1, 2*n_feat)\n","        self.timeembed3 = EmbedFC(1, n_feat)\n","        self.contextembed1 = EmbedFC(n_classes, 2*n_feat)\n","        self.contextembed2 = EmbedFC(n_classes, 2*n_feat)\n","        self.contextembed3 = EmbedFC(n_classes, n_feat)\n","        self.up0 = nn.Sequential(\n","            nn.ConvTranspose2d(2 * n_feat, 2 * n_feat, 4, 4),\n","            nn.GroupNorm(8, 2 * n_feat),\n","            nn.ReLU(),\n","        )\n","\n","        self.up1 = UnetUp(4 * n_feat, 2 * n_feat)\n","        self.up2 = UnetUp(4 * n_feat, n_feat)\n","        self.up3 = UnetUp(2 * n_feat, n_feat)\n","        self.out = nn.Sequential(\n","            nn.Conv2d(2 * n_feat, n_feat, 3, 1, 1),\n","            nn.GroupNorm(8, n_feat),\n","            nn.ReLU(),\n","            nn.Conv2d(n_feat, self.in_channels, 3, 1, 1),\n","        )\n","\n","    def forward(self, x, c, t, context_mask):\n","\n","        x = self.init_conv(x)\n","        down1 = self.down1(x)\n","        down2 = self.down2(down1)\n","        down3 = self.down3(down2)\n","        hiddenvec = self.to_vec(down3)\n","\n","        c = nn.functional.one_hot(c, num_classes=self.n_classes).type(torch.float)\n","\n","        context_mask = context_mask[:, None]\n","        context_mask = context_mask.repeat(1,self.n_classes)\n","        context_mask = (-1*(1-context_mask))\n","        c = c * context_mask\n","\n","        cemb1 = self.contextembed1(c).view(-1, self.n_feat * 2, 1, 1)\n","        temb1 = self.timeembed1(t).view(-1, self.n_feat * 2, 1, 1)\n","        cemb2 = self.contextembed2(c).view(-1, self.n_feat*2, 1, 1)\n","        temb2 = self.timeembed2(t).view(-1, self.n_feat*2, 1, 1)\n","        cemb3 = self.contextembed3(c).view(-1, self.n_feat, 1, 1)\n","        temb3 = self.timeembed3(t).view(-1, self.n_feat, 1, 1)\n","\n","        up1 = self.up0(hiddenvec)\n","        up2 = self.up1(cemb1*up1+ temb1, down3)\n","        up3 = self.up2(cemb2*up2+ temb2, down2)\n","        up4 = self.up3(cemb3*up3+ temb3, down1)\n","        out = self.out(torch.cat((up4, x), 1))\n","        return out\n"],"metadata":{"id":"4XxAM8XmEnz1","executionInfo":{"status":"ok","timestamp":1715889395132,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# If you want to examine the model in more detail\n","# model_preview = ContextUnet(in_channels=3, n_feat=128, n_classes=10)\n","# print(model_preview)"],"metadata":{"id":"iW5h9Iiejnxw","executionInfo":{"status":"ok","timestamp":1715889395132,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def ddpm_schedules(beta1, beta2, T):\n","\n","    assert beta1 < beta2 < 1.0\n","\n","    beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n","    sqrt_beta_t = torch.sqrt(beta_t)\n","    alpha_t = 1 - beta_t\n","    log_alpha_t = torch.log(alpha_t)\n","    alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n","\n","    sqrtab = torch.sqrt(alphabar_t)\n","    oneover_sqrta = 1 / torch.sqrt(alpha_t)\n","\n","    sqrtmab = torch.sqrt(1 - alphabar_t)\n","    mab_over_sqrtmab_inv = (1 - alpha_t) / sqrtmab\n","\n","    return {\n","        \"alpha_t\": alpha_t,  # \\alpha_t\n","        \"oneover_sqrta\": oneover_sqrta,  # 1/\\sqrt{\\alpha_t}\n","        \"sqrt_beta_t\": sqrt_beta_t,  # \\sqrt{\\beta_t}\n","        \"alphabar_t\": alphabar_t,  # \\bar{\\alpha_t}\n","        \"sqrtab\": sqrtab,  # \\sqrt{\\bar{\\alpha_t}}\n","        \"sqrtmab\": sqrtmab,  # \\sqrt{1-\\bar{\\alpha_t}}\n","        \"mab_over_sqrtmab\": mab_over_sqrtmab_inv,  # (1-\\alpha_t)/\\sqrt{1-\\bar{\\alpha_t}}\n","    }"],"metadata":{"id":"cQMxQ6eQE2YK","executionInfo":{"status":"ok","timestamp":1715889395132,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class DDPM(nn.Module):\n","    def __init__(self, nn_model, betas, n_T, device, drop_prob=0.1):\n","        super(DDPM, self).__init__()\n","        self.nn_model = nn_model.to(device)\n","\n","        for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n","            self.register_buffer(k, v)\n","\n","        self.n_T = n_T\n","        self.device = device\n","        self.drop_prob = drop_prob\n","        self.loss_mse = nn.MSELoss()\n","\n","    def forward(self, x, c):\n","\n","        _ts = torch.randint(1, self.n_T+1, (x.shape[0],)).to(self.device)\n","        noise = torch.randn_like(x)\n","\n","        x_t = (\n","            self.sqrtab[_ts, None, None, None] * x\n","            + self.sqrtmab[_ts, None, None, None] * noise\n","        )\n","\n","        context_mask = torch.bernoulli(torch.zeros_like(c)+self.drop_prob).to(self.device)\n","\n","        return self.loss_mse(noise, self.nn_model(x_t, c, _ts / self.n_T, context_mask))\n","\n","    def sample(self, n_sample, size, device, guide_w = 0.0):\n","\n","        x_i = torch.randn(n_sample, *size).to(device)\n","        c_i = torch.arange(0,10).to(device)\n","        c_i = c_i.repeat(int(n_sample/c_i.shape[0]))\n","\n","        context_mask = torch.zeros_like(c_i).to(device)\n","\n","        c_i = c_i.repeat(2)\n","        context_mask = context_mask.repeat(2)\n","        context_mask[n_sample:] = 1.\n","\n","        x_i_store = []\n","        print()\n","        for i in range(self.n_T, 0, -1):\n","            print(f'sampling timestep {i}',end='\\r')\n","            t_is = torch.tensor([i / self.n_T]).to(device)\n","            t_is = t_is.repeat(n_sample,1,1,1)\n","\n","            x_i = x_i.repeat(2,1,1,1)\n","            t_is = t_is.repeat(2,1,1,1)\n","\n","            z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n","\n","            eps = self.nn_model(x_i, c_i, t_is, context_mask)\n","            eps1 = eps[:n_sample]\n","            eps2 = eps[n_sample:]\n","            eps = (1+guide_w)*eps1 - guide_w*eps2\n","            x_i = x_i[:n_sample]\n","            x_i = (\n","                self.oneover_sqrta[i] * (x_i - eps * self.mab_over_sqrtmab[i])\n","                + self.sqrt_beta_t[i] * z\n","            )\n","            if i%20==0 or i==self.n_T or i<8:\n","                x_i_store.append(x_i.detach().cpu().numpy())\n","\n","        x_i_store = np.array(x_i_store)\n","        return x_i, x_i_store"],"metadata":{"id":"2LZiuXktE2-y","executionInfo":{"status":"ok","timestamp":1715889395132,"user_tz":-180,"elapsed":3,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def unorm(x):\n","    xmax = x.max((0,1))\n","    xmin = x.min((0,1))\n","    return(x - xmin)/(xmax - xmin)\n","\n","def norm_all(store, n_t, n_s):\n","    nstore = np.zeros_like(store)\n","    for t in range(n_t):\n","        for s in range(n_s):\n","            nstore[t,s] = unorm(store[t,s])\n","    return nstore\n","\n","def norm_torch(x_all):\n","    x = x_all.cpu().numpy()\n","    xmax = x.max((2,3))\n","    xmin = x.min((2,3))\n","    xmax = np.expand_dims(xmax,(2,3))\n","    xmin = np.expand_dims(xmin,(2,3))\n","    nstore = (x - xmin)/(xmax - xmin)\n","    return torch.from_numpy(nstore)"],"metadata":{"id":"WH3uYkUhE4pP","executionInfo":{"status":"ok","timestamp":1715889395133,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def train_cifar10():\n","\n","    # hyperparameters\n","    # I've trained the model for 800 epochs, so 100 epoch will be insufficient\n","    # Weights of the model which has trained for 800 epochs are available\n","    n_epoch = 100\n","    batch_size = 64\n","    n_T = 2000\n","    device = \"cuda:0\"\n","    n_classes = 10\n","    n_feat = 256\n","    lrate = 1e-4\n","    save_model = True\n","    save_dir = '/content/drive/MyDrive/ddpm_sonuclar/outputs_13/' # /content/drive/MyDrive/...\n","    ws_test = [0.0, 2.0, 4.0] # strength of generative guidance, 0 means no guidance\n","\n","    ddpm = DDPM(nn_model=ContextUnet(in_channels=3, n_feat=n_feat, n_classes=n_classes), betas=(1e-4, 0.02), n_T=n_T, device=device, drop_prob=0.1)\n","    ddpm.to(device)\n","\n","    tf = transforms.Compose(\n","        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n","    )\n","    dataset = CIFAR10(\"./data\", train=True, download=True, transform=tf)\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=5)\n","    optim = torch.optim.AdamW(ddpm.parameters(), lr=lrate, weight_decay=0.1)\n","\n","    for ep in range(n_epoch):\n","        print(f'epoch {ep}')\n","        ddpm.train()\n","\n","        optim.param_groups[0]['lr'] = lrate*(1-ep/n_epoch)\n","\n","        pbar = tqdm(dataloader)\n","        loss_ema = None\n","        for x, c in pbar:\n","            optim.zero_grad()\n","            x = x.to(device)\n","            c = c.to(device)\n","            loss = ddpm(x, c)\n","            loss.backward()\n","            if loss_ema is None:\n","                loss_ema = loss.item()\n","            else:\n","                loss_ema = 0.95 * loss_ema + 0.05 * loss.item()\n","            pbar.set_description(f\"loss: {loss_ema:.4f}\")\n","            optim.step()\n","\n","        ddpm.eval()\n","        with torch.no_grad():\n","\n","            n_sample = 4*n_classes\n","            for w_i, w in enumerate(ws_test):\n","                if ep>=97:#ep>=794 or ep%50==0: #ep == int(n_epoch-1):\n","                  x_gen, x_gen_store = ddpm.sample(40, (3, 32, 32), device, guide_w=w)\n","                  n_sample_ = 40\n","                  nrows = 4\n","                  ncols = n_sample_//nrows\n","                  sx_gen_store = np.moveaxis(x_gen_store,2,4)\n","                  nsx_gen_store = norm_all(sx_gen_store, sx_gen_store.shape[0], n_sample_)\n","\n","                  grid = make_grid(norm_torch(x_gen), nrow=ncols)\n","                  save_image(grid, save_dir + f\"image_ep{ep}_w{w}.png\")\n","                  print('saved image at ' + save_dir + f\"image_ep{ep}_w{w}.png\")\n","\n","                if ep == int(n_epoch-1): #if ep%100==0 or ep == int(n_epoch-1)\n","                    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=True,figsize=(ncols, nrows))\n","\n","                    def animate(i, store):\n","                        print(f'gif animating frame {i} of {store.shape[0]}', end='\\r')\n","                        plots = []\n","                        for row in range(nrows):\n","                            for col in range(ncols):\n","                                axs[row, col].clear()\n","                                axs[row, col].set_xticks([])\n","                                axs[row, col].set_yticks([])\n","                                plots.append(axs[row, col].imshow(store[i,(row*n_classes)+col]))\n","\n","                        return plots\n","\n","                    ani = FuncAnimation(fig, animate, fargs=[nsx_gen_store],  interval=200, blit=False, repeat=True, frames=nsx_gen_store.shape[0])\n","                    ani.save(save_dir + f\"gif_ep{ep}_w{w}.gif\", dpi=100, writer=PillowWriter(fps=5))\n","                    print('saved image at ' + save_dir + f\"gif_ep{ep}_w{w}.gif\")\n","        # save model\n","        if save_model and ep == int(n_epoch-1):\n","            torch.save(ddpm.state_dict(), save_dir + f\"model_{ep}.pth\")\n","            print('saved model at ' + save_dir + f\"model_{ep}.pth\")"],"metadata":{"id":"dxcnsUOvFC9T","executionInfo":{"status":"ok","timestamp":1715889395133,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train_cifar10()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"NNxbByZ2FEJP","outputId":"3769e80f-0d21-4348-ce17-f5b67ea7cdf2","executionInfo":{"status":"error","timestamp":1715889417676,"user_tz":-180,"elapsed":22547,"user":{"displayName":"Ramazan Karatay","userId":"16941807363943876499"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:12<00:00, 13267290.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","epoch 0\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/782 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","loss: 0.2732:   5%|▍         | 39/782 [00:05<01:37,  7.59it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-bd082d09d4d5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_cifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-cdb52add6f04>\u001b[0m in \u001b[0;36mtrain_cifar10\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mloss_ema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mloss_ema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_ema\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.05\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loss: {loss_ema:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}